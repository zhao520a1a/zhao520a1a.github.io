<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>白话科普 | AI绘画是如何生成图像的？ | 发光の金子吖</title><meta name="author" content="Golden"><meta name="copyright" content="Golden"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="写在前面所有AI应用的基本范式，都可以说：“先喂给它很多数据，然后让它找到其中的特征和规律，最后让它生成新的数据”，而AI绘画也不例外，通过扔进去大量真实的图片让AI不断去了解、认识和学习，然后根据训练效果，自己生成图片。 - 废话文学 下面主要通过白话的方式阐述AI绘画原理，适用于泛AIGC爱好者阅读和学习了解，算法原理略去了很多细节。目的是让大家大概明白了AI绘画是如何工作的，共勉。﻿本文主要">
<meta property="og:type" content="article">
<meta property="og:title" content="白话科普 | AI绘画是如何生成图像的？">
<meta property="og:url" content="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/index.html">
<meta property="og:site_name" content="发光の金子吖">
<meta property="og:description" content="写在前面所有AI应用的基本范式，都可以说：“先喂给它很多数据，然后让它找到其中的特征和规律，最后让它生成新的数据”，而AI绘画也不例外，通过扔进去大量真实的图片让AI不断去了解、认识和学习，然后根据训练效果，自己生成图片。 - 废话文学 下面主要通过白话的方式阐述AI绘画原理，适用于泛AIGC爱好者阅读和学习了解，算法原理略去了很多细节。目的是让大家大概明白了AI绘画是如何工作的，共勉。﻿本文主要">
<meta property="og:locale">
<meta property="og:image" content="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif">
<meta property="article:published_time" content="2023-10-03T16:00:00.000Z">
<meta property="article:modified_time" content="2023-10-04T14:16:18.520Z">
<meta property="article:author" content="Golden">
<meta property="article:tag" content="ai">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif"><link rel="shortcut icon" href="/img/logo.png"><link rel="canonical" href="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '白话科普 | AI绘画是如何生成图像的？',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-10-04 22:16:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0-rc1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif')"><nav id="nav"><span id="blog-info"><a href="/" title="发光の金子吖"><img class="site-icon" src="/img/logo.png"/><span class="site-name">发光の金子吖</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">白话科普 | AI绘画是如何生成图像的？</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-03T16:00:00.000Z" title="发表于 2023-10-04 00:00:00">2023-10-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-10-04T14:16:18.520Z" title="更新于 2023-10-04 22:16:18">2023-10-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/">内部原理</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="白话科普 | AI绘画是如何生成图像的？"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>所有AI应用的基本范式，都可以说：<code>“先喂给它很多数据，然后让它找到其中的特征和规律，最后让它生成新的数据”</code>，而AI绘画也不例外，通过扔进去大量真实的图片让AI不断去了解、认识和学习，然后根据训练效果，自己生成图片。 - 废话文学</p>
<p>下面主要通过白话的方式阐述AI绘画原理，适用于泛AIGC爱好者阅读和学习了解，算法原理略去了很多细节。目的是让大家大概明白了AI绘画是如何工作的，共勉。﻿本文主要将以 Stable Diffusion 的为例讲解 AI 绘画的基本原理。</p>
<table>
<thead>
<tr>
<th>术语</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Diffusion Mode</td>
<td>扩散模型是一种深度学习模型，被设计用来生成与训练数据相似的新数据。</td>
</tr>
<tr>
<td>LDM(Latent Diffusion Mode)</td>
<td>LDM潜在扩散模型是扩散模型的一种变体</td>
</tr>
<tr>
<td>CLIP(Contrastive Language-Image Pre-Training)</td>
<td>CLIP 是一种用于匹配图像和文本的预训练神经网络模型</td>
</tr>
<tr>
<td>U-Net</td>
<td>U-Net是一种U型结构的用于图像分割的神经网络模型</td>
</tr>
<tr>
<td>VAE( variational autoencoder)</td>
<td>VAE 变分自编码器是一个生成模型，一种无监督的学习数据分布方法，</td>
</tr>
</tbody></table>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>当前AI绘画的效果（普通人输入一句话，几秒钟画出来的作品）：﻿</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/1.jpg" alt="1" style="zoom:67%;">

<p>现在的 AI 绘画工具集，也是五花八门… </p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/AI%20%E5%B7%A5%E5%85%B7%E9%9B%86.jpg" alt="AI 工具集" style="zoom:67%;">


<p>AI 工具集导航网站：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.ainav.cn/">https://www.ainav.cn/</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://ai-bot.cn/#term-7">https://ai-bot.cn/#term-7</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.ainavpro.com/">https://www.ainavpro.com/</a></p>
</li>
</ul>
<h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><p>AI绘画原理可以简单概括为”<strong>降噪画图</strong>“，即：<code>先随机生成一张马赛克图片，然后根据文字描述逐步去除马赛克，最终将能看清图片展示出来就可以了</code>，这好比随机给了AI一块石头，让他按照你的描述去雕刻出一个作品。</p>
<blockquote>
<p>给你3s停留时间，请将这句话在心中重复几遍，可以大声念出来，让我看看那个显眼包不好好听讲！！</p>
</blockquote>
<p>其实上面所说的“马赛克图片”，只是我给它起的小名，它的大名中叫“噪声图”。</p>
<p>AI绘画的过程可以分为2个步骤：</p>
<ul>
<li><p>步骤1： 理解语义，怎样学习文字描述和图片的联系；</p>
</li>
<li><p>步骤2： 生成图片，基于噪声图+描述生成图片；</p>
</li>
</ul>
<p>移除像素 Vs 添加噪声？</p>
<p>  因为直接移除像素会导致信息丧失，添加噪声则可以让模型更加学习到图片的特征。</p>
<blockquote>
<p>通过上面的表述，可以拆解成了几个核心问题，只要搞清楚这五个问题，相信你AI绘画的底层逻辑也就清晰了。</p>
</blockquote>
<h1 id="问题1：AI是怎么知道文字描述的是什么？"><a href="#问题1：AI是怎么知道文字描述的是什么？" class="headerlink" title="问题1：AI是怎么知道文字描述的是什么？"></a>问题1：AI是怎么知道文字描述的是什么？</h1><p>首先大家要明白，机器其实并不会理解人类的语言，我们需要通过喂给它各种各样的图片数据，计算机会通过分析这些图片的特征，学习它们的风格和结构 。本质上要解决的问题是：如何将输入的一段话，就转换成了这次生成图像所需要的全部特征向量。 </p>
<p>这里面就不得不提，在21 Openai年推出的<a target="_blank" rel="noopener" href="https://github.com/openai/CLIP">OpenCLIP</a>，OpenCLIP 的出现彻底打通了文字和图像之间的鸿沟。它的作用就是把文字和图像联系起来。</p>
<h2 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h2><h3 id="如何构建一个庞大的图文数据库？"><a href="#如何构建一个庞大的图文数据库？" class="headerlink" title="如何构建一个庞大的图文数据库？"></a>如何构建一个庞大的图文数据库？</h3><p>模型训练需要非常多的图片，数据从哪里来?</p>
<ol>
<li><p>爬取信息：通过爬虫脚本抓取大量图片</p>
</li>
<li><p>打标签：每爬到一张图片后，都从许多维度来描述这个图，给图片打上对应的标签以及描述。实际上，大多是根据从网络上抓取的图像以及其 “alt” 标签进行训练的。</p>
</li>
<li><p>存储图文信息对：根据这些信息构建出一个超多维的数据库，每一个维度都会和其他维度交叉起来，此时相似的维度会相对靠拢在一起。 最终构建了一个超多维的数据库，包含上亿的“文本+图片”的信息对。</p>
</li>
</ol>
<h3 id="如何建立文本和图像的关联？"><a href="#如何建立文本和图像的关联？" class="headerlink" title="如何建立文本和图像的关联？"></a>如何建立文本和图像的关联？</h3><p>有了数据库，如何提供文本图像匹配能力，需要是不断地通过大量数据来训练CLIP去关联、认识图片和文字，并且根据和答案的比对，不断地矫正，最后达到精确匹配关键词和特征向量。 </p>
<p>训练时用一组组文字和图像做对比， 通过文本编码器和图像编码器，分别的得到文本特征和图像特征。拿图像和文本编码后的特征去<strong>计算出一个相似性矩阵</strong>。这样训练后，当我们录入一段文本描述，CLIP模型就会根据描述去数据库里从多个维度进行相似度的匹配。当找到最相似的维度描述后，把这些图像特征全部融合到一起，构建出本次要产出的图像的<strong>总特征向量集。</strong> </p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/CLIP.png" alt="CLIP" style="zoom:67%;">



<p>简要流程：</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/clip.jpg" alt="clip" style="zoom:67%;">

<p>特别注意：我们可以直接用训练好的 clip 模型的文本编码器，这样当我们输入的一段话，就转换成了这次生成相关的文本特征向量，也就是所谓的“AI已经理解了你想画什么样的画了”。</p>
<h1 id="问题2：原始的噪声图是怎么来的？"><a href="#问题2：原始的噪声图是怎么来的？" class="headerlink" title="问题2：原始的噪声图是怎么来的？"></a>问题2：原始的噪声图是怎么来的？</h1><p>噪声图是Diffusion Model(扩散模型)生成的，那 Diffusion Model(扩散模型）又是什么？</p>
<h2 id="Diffusion-Model"><a href="#Diffusion-Model" class="headerlink" title="Diffusion Model"></a>Diffusion Model</h2><blockquote>
<p> 目前主流AI绘画工具图片生成的核心都是扩散模型。特别说明，Diffusion Model  的应用不只局限于图片，其他音频、视频等场景也有。</p>
</blockquote>
<p>扩散模型是在2015年相关论文里提出的， 主要包含2个过程，分别是前向扩散和逆向扩散，具体如下图所示：</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-%E5%8A%A0%E5%99%AA-6230131.jpg" alt="扩散模型-加噪" style="zoom:67%;">

<p>前向扩散：是一个通过算法不断叠加噪声的过程，可以简单理解为不断对图片进行马赛克处理。如图从右到左做模糊处理，直至最后看不出来是什么；</p>
<p>这个过程可以想象成你在发朋友圈照片时，想屏蔽一些信息，所以使用“编辑”功能不断地对某些区域进行涂抹，直到这个区域看不清原本的内容了。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-%E5%8E%BB%E5%99%AA.jpg" alt="扩散模型-去噪" style="zoom:67%;">

<p>逆向扩散：是一个去噪推断过程。如图从左到右做处理，一步步把一个图片逐渐去除噪声，变清晰的过程。逐步朝着目标图像进行演变 。</p>
<h1 id="问题3：如何根据噪声生成图片？"><a href="#问题3：如何根据噪声生成图片？" class="headerlink" title="问题3：如何根据噪声生成图片？"></a>问题3：如何根据噪声生成图片？</h1><p>毫无疑问，逆向扩散的想法既巧妙又优雅， 但如何实现它呢？首先需要让AI知道图像中添加了多少噪声，教其预测噪声</p>
<h2 id="如何训练一个噪声预测器-noise-predictor-？"><a href="#如何训练一个噪声预测器-noise-predictor-？" class="headerlink" title="如何训练一个噪声预测器(noise predictor)？"></a>如何训练一个噪声预测器(noise predictor)？</h2><p>主要通过 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/U-Net">U-Net 模型</a> + Scheduler 的组合，具体的训练过程如下。</p>
<h3 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a>U-Net</h3><p><strong>U-Net在不断的训练过程中主要学会了一件事，那就是去噪！去噪！还是tmd去噪！</strong></p>
<p>Stable Diffusion中U-Net的训练一共分四步：</p>
<ol>
<li><p>随机选取一个示例：从训练集中选取一张加噪过的图片和噪声强度。</p>
</li>
<li><p>预测标记出无用的噪声：将数据输入U-Nnet，并且预测噪声矩阵。</p>
</li>
<li><p>与正确答案对比：将预测的噪声矩阵和实际噪声矩阵（Label）进行误差的计算。</p>
</li>
<li><p>不断纠正：通过反向传播更新U-Net的参数。<br> 本质是一个强化学习的过程。</p>
</li>
</ol>
<p>U-Net 的大体结构如下：</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM3MTAyMDkz,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom:67%;">



<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>例如选择一张猫的照片作为训练图像，最终生成一个随机噪声图像。通过在一定数量的步骤中加入这个嘈杂的图像来破坏训练图像。然后让它告诉我们添加了多少噪声。这是通过调整其权重并向其展示正确答案来完成的。</p>
<p>当我们试图在每个采样步骤中获得预期的噪声，这被称为噪声计划(Noise schedule)。我们可以选择在每一步减去相同数量的噪声，也可以在开始时减去更多的噪声。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/%E6%94%B9%E8%BF%9B%E7%9A%84%E5%8E%BB%E9%99%8D%E5%99%AA%E6%A8%A1%E5%9E%8B.jpg" alt="改进的去降噪模型" style="zoom:67%;">

<p>采样器在每一步中减去足够的噪声，以达到下一步的预期噪声。这就是您在逐步的图像中看到的内容。</p>
<p>虽然这个步骤无法做到图片生成，但对训练样本分类准确性至关重要。经过训练后，我们有了一个能够估计图像中添加噪声的噪声预测器。</p>
<h3 id="噪声算法"><a href="#噪声算法" class="headerlink" title="噪声算法"></a>噪声算法</h3><p>即噪声的算法此前是依据<strong>正态分布</strong>给图像逐步增加噪声，到了2020年加噪声的过程被改为根据<strong>余弦相似度</strong>的规律来处理。</p>
<h2 id="如何使用噪声预测器？"><a href="#如何使用噪声预测器？" class="headerlink" title="如何使用噪声预测器？"></a>如何使用噪声预测器？</h2><p>首先生成一个完全随机的图像，并请噪声预测器告诉我们噪声；然后我们从原始图像中减去这个估计的噪声。重复这个过程几次。你将得到一张猫或狗的图像。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/a%20(6)-20231003162740453.png" alt="6" style="zoom:67%;">

 

<p>这里看下看下不断预测噪声的整个过程：</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif" alt="stable diffusion euler" style="zoom: 50%;">



<h1 id="问题4：如何根据描述去除无用噪声？"><a href="#问题4：如何根据描述去除无用噪声？" class="headerlink" title="问题4：如何根据描述去除无用噪声？**"></a>问题4：如何根据描述去除无用噪声？**</h1><p> AI是怎么能够按照我描述的来去除无用的噪声，其实这就是一个模型训练的过程。目的引导噪声预测器，使预测的噪声在从图像中减去后能给我们想要的结果。</p>
<ol>
<li>为了加入文本特征， U-Net 里添加了注意力机制。</li>
<li>通过一个无分类器引导（Classifier-Free Guidance，CFG）的方法，放大具有文本特征的噪声，达到加强引导生成具有文本特征的图片的效果。</li>
</ol>
<p>看看在每一步中添加了什么信息。</p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/images/stable-diffusion/diffusion-steps-all-loop.webm">https://jalammar.github.io/images/stable-diffusion/diffusion-steps-all-loop.webm</a> </p>
<h1 id="问题5：如何提升运算效率？"><a href="#问题5：如何提升运算效率？" class="headerlink" title="问题5：如何提升运算效率？"></a>问题5：如何提升运算效率？</h1><p>由于上面的扩散过程是在图像空间中进行的。而图像空间非常庞大，导致计算上非常非常慢。 </p>
<p>想想看：一个512×512的图像有三个颜色通道（红、绿和蓝），是一个786,432维的空间！（你需要为一个图像指定这么多值。）我们可以使用了一些技巧，让扩散模型位于像素空间来加快模型的速度，但仍然不够。</p>
<p>解法就是<strong>降维数据运算</strong>！</p>
<h2 id="LDM-Latent-Diffusion-Mode"><a href="#LDM-Latent-Diffusion-Mode" class="headerlink" title="LDM(Latent Diffusion Mode)"></a>LDM(Latent Diffusion Mode)</h2><p>LDM 主要区别在于它通过压缩图片降低维度，压缩后所在的空间，叫潜在空间。这令计算量大幅度减少，降低了对硬件的要求。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/image-20231002145457224.png" alt="image-20231002145457224" style="zoom:67%;">

<h2 id="VAE-variational-autoencoder"><a href="#VAE-variational-autoencoder" class="headerlink" title="VAE( variational autoencoder)"></a>VAE( variational autoencoder)</h2><p>LDM 模型将将图像压缩到潜在空间，是通过变分自编码器VAE( variational autoencoder)技术来实现的</p>
<p>VAE 主要通过编码器生成特征，然后解码器重构出原来的特征，让重构出来的特征和输入的特征尽可能相似即可。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/image-85-1024x477.png" alt="img" style="zoom:67%;">



<p>具体过程如下：我们先通过 VAE 编码器把图片压缩到潜在空间，然后在潜在空间中训练扩缩模型。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/image-20231003160939337.png" alt="image-20231003160939337" style="zoom:67%;">

<p>但压缩还原是还是那边有些失真。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/image-20231003172015812.png" alt="image-20231003172015812" style="zoom:50%;">

<p> 注意：</p>
<ul>
<li><p>VAE生成不只简单重构原来的特征，生成的特征是根据分布的均值。</p>
</li>
<li><p>VAE 是预先训练好的，LDM 可以直接拿来用。</p>
</li>
</ul>
<h1 id="问题6：如何稳定控制出图效果呢？"><a href="#问题6：如何稳定控制出图效果呢？" class="headerlink" title="问题6：如何稳定控制出图效果呢？"></a>问题6：如何稳定控制出图效果呢？</h1><p>目前大模型最不可控的地方就是它的不稳定性。那么如果想要稍微控制下AI绘画的效果，有什么好的方法吗？这里给出四种方式，供大家参考。</p>
<p>##调整描述</p>
<p>本质上是改变通过文本匹配到的图像特征向量集合，所以最终的出图会不断地调整、优化。<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/3.jpg" alt="3" style="zoom:67%;"></p>
<h2 id="垫图-img2img"><a href="#垫图-img2img" class="headerlink" title="垫图(img2img)"></a>垫图(img2img)</h2><p>主流的AI绘画软件和模型都支持垫图功能，也就是你上传一张图，然后根据你这张图的轮廓或者大概样式，再生成一张图。<br>本质是在样图加噪声，然后拿这个叠噪后的图片作为基础再让AI进行去噪操作，所以最终风格、结构和原图相似的概率很大。概率上叠加的噪声越少，越和原图相似。</p>
<h2 id="修改参数"><a href="#修改参数" class="headerlink" title="修改参数"></a>修改参数</h2><p>通过插件中设置的条件或要求来控制生成的效果。<br>本质上它把去噪模型整个复制了一遍，然后两个模型并行处理，一个做常态去噪，一个做条件去噪，最后再合并，达到稳定控制的效果。</p>
<h2 id="自建图库"><a href="#自建图库" class="headerlink" title="自建图库"></a>自建图库</h2><p>当然你也可以自己建个图像库，单独拿大量数据训练，然后不断地训练大模型去识别这些图像，本质上对已有模型的微调</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>利用 CLIP 模型的编码器，把文字转换成向量作为输入；</p>
<p>通过 Diffusion Model 生成图像特征；</p>
<p>通过 VAE 模型的解码器，把图像特征还原成图片。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/AI_%E7%BB%98%E7%94%BB%20(1).png" alt="AI_绘画 (1)" style="zoom:67%;">

<p>由此，我们可以看到三个主要组件（每个组件都有自己的神经网络）：</p>
<ul>
<li><p>通过 Clip 文本编码器，把文字转换向量；<br>输入：文本。<br>输出： 77 个标记嵌入向量，每个向量有 768 个维度。</p>
</li>
<li><p>UNet + Scheduler，用于在信息（潜在）空间中逐步处理&#x2F;扩散信息。<br>输入：文本嵌入和由噪声组成的起始多维数组（数字结构化列表，也称为张量）。<br>输出： 经过处理的信息数组</p>
</li>
</ul>
<p>注：U-Net并不直接输出无噪声的原数据，而是去预测原数据上所加过的噪声。</p>
<ul>
<li>通过 VAE 解码器将信息数组绘制最终图像。<br>输入： 处理过的信息数组（维数：(4,64,64)<br>输出： 生成的图像（尺寸：（3, 512, 512），即（红&#x2F;绿&#x2F;蓝、宽、高）</li>
</ul>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/AI_%E7%BB%98%E7%94%BB.png" alt="AI_绘画" style="zoom:67%;">

<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/v2-9a4fed959f7750d50aea98a5eb7df3ca_720w.webp" alt="img" style="zoom:67%;">


<h1 id="一点思考"><a href="#一点思考" class="headerlink" title="一点思考"></a>一点思考</h1><p> AI 只是一个能够提高生产力工具而已，目前还是存在很多问题，例如 AI 绘画风格有些相似，因为便于计算，一些细节还是很粗糙，例如：人物的手、图片的文字不清晰等等。</p>
<img src="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/%E7%94%B7%E7%A8%8B%E5%BA%8F%E5%91%98.png" alt="男程序员" style="zoom:50%;">



<p>其实目前的 AI 所具备能力其实很基础，但之所以认为为之惊叹甚至恐慌，某种程度上，只是人们对创造力的获取看的很难，然而事实并非如此。</p>
<p>人所具有创造力只是一种很原始的基础能力而已，通常的创造力，都是基于原有知识的创新，即：旧东西新组合。而更为强大的创造力，如：相对论、量子计算机等，这种创造来源未知。而AI都是基于既有知识训练，不太能具备此种创造力。</p>
<p>此外，不会存在通用上的AI，未来一定是针对某一领域的具体式AI，如：文字-聊天，图像-绘画，声音-音乐等，作为人类的助手形式存在。<code>不必执着于过去，因为改变终将到来！</code></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[视频]Stable Diffusion 原理介绍：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vV4y1D7LP">https://www.bilibili.com/video/BV1vV4y1D7LP</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Yu411x7mg">https://www.bilibili.com/video/BV1Yu411x7mg</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1CIpzeNxIhU">https://www.youtube.com/watch?v=1CIpzeNxIhU</a></p>
<p>[文章]Stable Diffusion 原理介绍：</p>
<p><a target="_blank" rel="noopener" href="https://stable-diffusion-art.com/how-stable-diffusion-work/">https://stable-diffusion-art.com/how-stable-diffusion-work/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.modevol.com/episode/clfwjxyw92kql01mu7j6i8q6w">https://www.modevol.com/episode/clfwjxyw92kql01mu7j6i8q6w</a></p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-stable-diffusion/">https://jalammar.github.io/illustrated-stable-diffusion/</a></p>
<p>CLIP模型介绍：<a target="_blank" rel="noopener" href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></p>
<p>OpenCLIP模型介绍：<a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a></p>
<p>Textual Inversion 介绍: <a target="_blank" rel="noopener" href="https://textual-inversion.github.io/">https://textual-inversion.github.io/</a></p>
<p>U-Net 介绍：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/642354007">https://zhuanlan.zhihu.com/p/642354007</a></p>
<p>VAE结构图出处：<a target="_blank" rel="noopener" href="https://towardsdatascience.com/vae-variational-autoencoders-how-to-employ-neural-networks-to-generate-new-images-bdeb216ed2c0">https://towardsdatascience.com/vae-variational-autoencoders-how-to-employ-neural-networks-to-generate-new-images-bdeb216ed2c0</a></p>
<p>各种微调模型方法对比：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=dVjMiJsuR5o">https://www.youtube.com/watch?v=dVjMiJsuR5o</a></p>
<p>Diffusion Models 公式 <a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></p>
<p>Latent Diffusion论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.10752.pdf">https://arxiv.org/pdf/2112.10752.pdf</a></p>
<p>DALLE2论文：<a target="_blank" rel="noopener" href="https://cdn.openai.com/papers/dall-e-2.pdf">https://cdn.openai.com/papers/dall-e-2.pdf</a></p>
<p>LoRA论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.09685.pdf">https://arxiv.org/pdf/2106.09685.pdf</a></p>
<p>Dreambooth 论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.12242.pdf">https://arxiv.org/pdf/2208.12242.pdf</a></p>
<p>ControlNet 论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2302.05543.pdf">https://arxiv.org/pdf/2302.05543.pdf</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://zhao520a1a.github.io">Golden</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/">https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhao520a1a.github.io" target="_blank">发光の金子吖</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">ai</a></div><div class="post_share"><div class="social-share" data-image="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/08/14/%E7%94%9F%E6%B4%BB%E5%B0%8F%E8%AE%B0/%E8%A7%A3%E6%9E%90%E4%B8%80%E5%BC%A0%E6%80%9D%E7%BB%B4%E8%84%91%E5%9B%BE%E8%83%8C%E5%90%8E%E7%9A%84%E7%A7%98%E5%AF%86%EF%BC%9F/" title="解析一张思维脑图背后的秘密？"><img class="cover" src="https://pica.zhimg.com/cfa176b783a272bff21a9acb14cbf3b4_1440w.jpg?source=172ae18b" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">解析一张思维脑图背后的秘密？</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/02/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/Copilot/" title="copilot 使用指南"><img class="cover" src="https://rewind.com/wp-content/uploads/2022/03/github-copilot-logo.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-02</div><div class="title">copilot 使用指南</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Golden</div><div class="author-info__description">一个乐观的悲观主义者</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/334383730"><i class="fab fa-bilibili"></i><span>关注一下</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zhao520a1a" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://space.bilibili.com/334383730" target="_blank" title="B 站"><i class="fab fa-bilibili"></i></a><a class="social-icon" href="https://zhao520a1a.github.io/about/index/qrCode.png" target="_blank" title="微信公众号"><i class="fab fa-weixin"></i></a><a class="social-icon" href="https://www.processon.com/u/5ab9cb2de4b018c271cab8d4/profile" target="_blank" title="ProcessOn"><i class="far fa-lightbulb"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">喜欢即可关注，关注即可进步，OVER!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%981%EF%BC%9AAI%E6%98%AF%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93%E6%96%87%E5%AD%97%E6%8F%8F%E8%BF%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">问题1：AI是怎么知道文字描述的是什么？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CLIP"><span class="toc-number">4.1.</span> <span class="toc-text">CLIP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%BA%9E%E5%A4%A7%E7%9A%84%E5%9B%BE%E6%96%87%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%9F"><span class="toc-number">4.1.1.</span> <span class="toc-text">如何构建一个庞大的图文数据库？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%96%87%E6%9C%AC%E5%92%8C%E5%9B%BE%E5%83%8F%E7%9A%84%E5%85%B3%E8%81%94%EF%BC%9F"><span class="toc-number">4.1.2.</span> <span class="toc-text">如何建立文本和图像的关联？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%982%EF%BC%9A%E5%8E%9F%E5%A7%8B%E7%9A%84%E5%99%AA%E5%A3%B0%E5%9B%BE%E6%98%AF%E6%80%8E%E4%B9%88%E6%9D%A5%E7%9A%84%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">问题2：原始的噪声图是怎么来的？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Diffusion-Model"><span class="toc-number">5.1.</span> <span class="toc-text">Diffusion Model</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%983%EF%BC%9A%E5%A6%82%E4%BD%95%E6%A0%B9%E6%8D%AE%E5%99%AA%E5%A3%B0%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87%EF%BC%9F"><span class="toc-number">6.</span> <span class="toc-text">问题3：如何根据噪声生成图片？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%99%AA%E5%A3%B0%E9%A2%84%E6%B5%8B%E5%99%A8-noise-predictor-%EF%BC%9F"><span class="toc-number">6.1.</span> <span class="toc-text">如何训练一个噪声预测器(noise predictor)？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#U-Net"><span class="toc-number">6.1.1.</span> <span class="toc-text">U-Net</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scheduler"><span class="toc-number">6.1.2.</span> <span class="toc-text">Scheduler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%99%AA%E5%A3%B0%E7%AE%97%E6%B3%95"><span class="toc-number">6.1.3.</span> <span class="toc-text">噪声算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%99%AA%E5%A3%B0%E9%A2%84%E6%B5%8B%E5%99%A8%EF%BC%9F"><span class="toc-number">6.2.</span> <span class="toc-text">如何使用噪声预测器？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%984%EF%BC%9A%E5%A6%82%E4%BD%95%E6%A0%B9%E6%8D%AE%E6%8F%8F%E8%BF%B0%E5%8E%BB%E9%99%A4%E6%97%A0%E7%94%A8%E5%99%AA%E5%A3%B0%EF%BC%9F"><span class="toc-number">7.</span> <span class="toc-text">问题4：如何根据描述去除无用噪声？**</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%985%EF%BC%9A%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E8%BF%90%E7%AE%97%E6%95%88%E7%8E%87%EF%BC%9F"><span class="toc-number">8.</span> <span class="toc-text">问题5：如何提升运算效率？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LDM-Latent-Diffusion-Mode"><span class="toc-number">8.1.</span> <span class="toc-text">LDM(Latent Diffusion Mode)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VAE-variational-autoencoder"><span class="toc-number">8.2.</span> <span class="toc-text">VAE( variational autoencoder)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%986%EF%BC%9A%E5%A6%82%E4%BD%95%E7%A8%B3%E5%AE%9A%E6%8E%A7%E5%88%B6%E5%87%BA%E5%9B%BE%E6%95%88%E6%9E%9C%E5%91%A2%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">问题6：如何稳定控制出图效果呢？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9E%AB%E5%9B%BE-img2img"><span class="toc-number">9.1.</span> <span class="toc-text">垫图(img2img)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%8F%82%E6%95%B0"><span class="toc-number">9.2.</span> <span class="toc-text">修改参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%BB%BA%E5%9B%BE%E5%BA%93"><span class="toc-number">9.3.</span> <span class="toc-text">自建图库</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">10.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83"><span class="toc-number">11.</span> <span class="toc-text">一点思考</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">12.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20%7C%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/" title="白话科普 | AI绘画是如何生成图像的？"><img src="https://zhao520a1a.github.io/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20|%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/cat_euler_15.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="白话科普 | AI绘画是如何生成图像的？"/></a><div class="content"><a class="title" href="/2023/10/04/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/AI/%E7%99%BD%E8%AF%9D%E7%A7%91%E6%99%AE%20%7C%20AI%E7%BB%98%E7%94%BB%E6%98%AF%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%9B%BE%E5%83%8F%E7%9A%84%EF%BC%9F/" title="白话科普 | AI绘画是如何生成图像的？">白话科普 | AI绘画是如何生成图像的？</a><time datetime="2023-10-03T16:00:00.000Z" title="发表于 2023-10-04 00:00:00">2023-10-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/14/%E7%94%9F%E6%B4%BB%E5%B0%8F%E8%AE%B0/%E8%A7%A3%E6%9E%90%E4%B8%80%E5%BC%A0%E6%80%9D%E7%BB%B4%E8%84%91%E5%9B%BE%E8%83%8C%E5%90%8E%E7%9A%84%E7%A7%98%E5%AF%86%EF%BC%9F/" title="解析一张思维脑图背后的秘密？"><img src="https://pica.zhimg.com/cfa176b783a272bff21a9acb14cbf3b4_1440w.jpg?source=172ae18b" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="解析一张思维脑图背后的秘密？"/></a><div class="content"><a class="title" href="/2023/08/14/%E7%94%9F%E6%B4%BB%E5%B0%8F%E8%AE%B0/%E8%A7%A3%E6%9E%90%E4%B8%80%E5%BC%A0%E6%80%9D%E7%BB%B4%E8%84%91%E5%9B%BE%E8%83%8C%E5%90%8E%E7%9A%84%E7%A7%98%E5%AF%86%EF%BC%9F/" title="解析一张思维脑图背后的秘密？">解析一张思维脑图背后的秘密？</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/09/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/Go/Go%20JSON%20%E4%B8%89%E6%96%B9%E5%8C%85%E5%93%AA%E5%AE%B6%E5%BC%BA%EF%BC%9F/" title="Go JSON 三方包哪家强？"><img src="https://cms.halovina.com/wp-content/uploads/2021/03/golang-json.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go JSON 三方包哪家强？"/></a><div class="content"><a class="title" href="/2023/05/09/%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/Go/Go%20JSON%20%E4%B8%89%E6%96%B9%E5%8C%85%E5%93%AA%E5%AE%B6%E5%BC%BA%EF%BC%9F/" title="Go JSON 三方包哪家强？">Go JSON 三方包哪家强？</a><time datetime="2023-05-08T16:00:00.000Z" title="发表于 2023-05-09 00:00:00">2023-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/02/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/%E6%8F%90%E6%95%88%E5%B8%B8%E8%AF%86/" title="提效常识"><img src="https://5b0988e595225.cdn.sohucs.com/images/20180702/8210193a4448400b8aa6cdb214899d78.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="提效常识"/></a><div class="content"><a class="title" href="/2023/05/02/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/%E6%8F%90%E6%95%88%E5%B8%B8%E8%AF%86/" title="提效常识">提效常识</a><time datetime="2023-05-01T16:00:00.000Z" title="发表于 2023-05-02 00:00:00">2023-05-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/02/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/Copilot/" title="copilot 使用指南"><img src="https://rewind.com/wp-content/uploads/2022/03/github-copilot-logo.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="copilot 使用指南"/></a><div class="content"><a class="title" href="/2023/02/02/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/Copilot/" title="copilot 使用指南">copilot 使用指南</a><time datetime="2023-02-01T16:00:00.000Z" title="发表于 2023-02-02 00:00:00">2023-02-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By Golden</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>